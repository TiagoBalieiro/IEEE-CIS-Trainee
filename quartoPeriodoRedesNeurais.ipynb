{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento e visualização dos dados"
      ],
      "metadata": {
        "id": "osS2V2QQAf1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv5DvJlAbGMt",
        "outputId": "3243197f-7ab3-4b31-a73a-83087e34b256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11509265043.0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = pd.read_csv('/content/creditcard.csv', engine='python')\n",
        "print(dataset['Time'].unique().sum())\n",
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base na documentação do dataset, sabe-se que ele é altamente desbalanceado. Das 284.807, apenas 492 são fraudes. Isso pode gerar um problema para a rede neural, que irá ser parcial para a classe em maior quantidade."
      ],
      "metadata": {
        "id": "nxx9Lqp3Ao_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separe a label das features e o dataset em subsets de treinamento e teste"
      ],
      "metadata": {
        "id": "5yiSfcvgCoWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.drop(['Time','Amount','Class'], axis=1).values\n",
        "y = dataset['Class'].values.reshape(-1, 1)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6lv7szaBi1m",
        "outputId": "664d4f8f-3855-403b-f1d4-b51fa69352d0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(284807, 28)\n",
            "(284807, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialização randômica dos pesos"
      ],
      "metadata": {
        "id": "4BXFCTq4G1Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inicializacaoPesos(tamanhoDaCamada):\n",
        "    pesos = []\n",
        "    bias = []\n",
        "    for i in range(len(tamanhoDaCamada) - 1):\n",
        "        pesos.append(np.random.randn(tamanhoDaCamada[i], tamanhoDaCamada[i + 1]) * 0.01)\n",
        "        bias.append(np.zeros((1, tamanhoDaCamada[i + 1])))\n",
        "    return pesos, bias\n"
      ],
      "metadata": {
        "id": "HQvNeo9JGx3d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defina a função de ativação e calcular sua derivada\n"
      ],
      "metadata": {
        "id": "bREZuxaYHoNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoide(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoideDerivada(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def reluDerivada(x):\n",
        "    return np.where(x > 0, 1, 0)"
      ],
      "metadata": {
        "id": "-0Vt49VrHuv3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treine o modelo testando diferentes valores de épocas e learning rate, identificando quando acontece Overfitting e Underfitting"
      ],
      "metadata": {
        "id": "NE99R_sgH_PW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feedforward(X, pesos, bias):\n",
        "    activations = [X]\n",
        "    input = X\n",
        "\n",
        "    for i in range(len(pesos) - 1):\n",
        "        z = np.dot(input, pesos[i]) + bias[i]\n",
        "        a = relu(z)\n",
        "        activations.append(a)\n",
        "        input = a\n",
        "\n",
        "    z = np.dot(input, pesos[-1]) + bias[-1]\n",
        "    output = sigmoide(z)\n",
        "    activations.append(output)\n",
        "\n",
        "    return activations\n",
        "\n",
        "def backpropagation(X, y, pesos, bias, activations, learningRate):\n",
        "    m = X.shape[0]\n",
        "    deltas = [None] * len(pesos)\n",
        "    L = len(pesos) - 1\n",
        "\n",
        "    output_error = activations[-1] - y\n",
        "    deltas[L] = output_error * sigmoideDerivada(activations[-1])\n",
        "\n",
        "    for i in range(L - 1, -1, -1):\n",
        "        deltas[i] = np.dot(deltas[i + 1], pesos[i + 1].T) * reluDerivada(activations[i + 1])\n",
        "\n",
        "    for i in range(len(pesos)):\n",
        "        pesos[i] -= learningRate * np.dot(activations[i].T, deltas[i]) / m\n",
        "        bias[i] -= learningRate * np.mean(deltas[i], axis=0, keepdims=True)\n",
        "\n",
        "    return pesos, bias"
      ],
      "metadata": {
        "id": "-7PbGylDIIHh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, y, tamanhoDaCamada, learningRate, epocas):\n",
        "    pesos, bias = inicializacaoPesos(tamanhoDaCamada)\n",
        "\n",
        "    for epoca in range(epocas):\n",
        "        activations = feedforward(X, pesos, bias)\n",
        "        pesos, bias = backpropagation(X, y, pesos, bias, activations, learningRate)\n",
        "\n",
        "        if epoca % 100 == 0:\n",
        "            loss = np.mean((y - activations[-1])**2)\n",
        "            print(f'Epoca {epoca}, Loss: {loss}')\n",
        "\n",
        "    return pesos, bias"
      ],
      "metadata": {
        "id": "rDQTfZbuJcTw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predicao(X, pesos, bias):\n",
        "    activations = feedforward(X, pesos, bias)\n",
        "    return (activations[-1] > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "HkQ_l27iKZSv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fazer as previsões nos dados de teste e avaliar o modelo"
      ],
      "metadata": {
        "id": "fzKAor3PMpcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avalaiando conjunto de teste com Learning Ratte = 0.01 e 1000 epocas."
      ],
      "metadata": {
        "id": "97T5RRPRqnIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tamanhoDasCamadas = [X_train.shape[1], 16, 1]\n",
        "\n",
        "pesos, bias = train(X_train, y_train, tamanhoDasCamadas, learningRate=0.01, epocas=1000)\n",
        "\n",
        "y_pred = predicao(X_test, pesos, bias)\n",
        "\n",
        "acuracia = np.mean(y_pred == y_test)\n",
        "print(f'Accuracy: {acuracia * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o106EcxVMt7l",
        "outputId": "fc6c8f91-48fb-4038-ed7a-1019f1d5cb84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 0, Loss: 0.2498719778080381\n",
            "Epoca 100, Loss: 0.22057816902627592\n",
            "Epoca 200, Loss: 0.19507272359982356\n",
            "Epoca 300, Loss: 0.17305983407141745\n",
            "Epoca 400, Loss: 0.15415606384198333\n",
            "Epoca 500, Loss: 0.13795431041975775\n",
            "Epoca 600, Loss: 0.12406378047010848\n",
            "Epoca 700, Loss: 0.1121308630085563\n",
            "Epoca 800, Loss: 0.10184716077441329\n",
            "Epoca 900, Loss: 0.092949858566766\n",
            "Accuracy: 99.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avaliando conjunto de train com Learning Ratte = 0.01 e 1000 epocas a fim de comparar com o conjunto de teste."
      ],
      "metadata": {
        "id": "bbLYjbmwrRm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tamanhoDasCamadas = [X_train.shape[1], 16, 1]\n",
        "\n",
        "pesos, bias = train(X_train, y_train, tamanhoDasCamadas, learningRate=0.01, epocas=1000)\n",
        "\n",
        "y_predTrain = predicao(X_train, pesos, bias)\n",
        "\n",
        "acuracia = np.mean(y_predTrain == y_train)\n",
        "print(f'Accuracy: {acuracia * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTTUPAdFnpyw",
        "outputId": "6b5d5474-046a-4742-a697-f6523926a9d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 0, Loss: 0.2500633973684645\n",
            "Epoca 100, Loss: 0.22075361051536535\n",
            "Epoca 200, Loss: 0.19523624353380858\n",
            "Epoca 300, Loss: 0.17321463266827306\n",
            "Epoca 400, Loss: 0.1543045940258705\n",
            "Epoca 500, Loss: 0.1380983971903174\n",
            "Epoca 600, Loss: 0.1242047655082461\n",
            "Epoca 700, Loss: 0.1122697316068186\n",
            "Epoca 800, Loss: 0.10198462661807348\n",
            "Epoca 900, Loss: 0.09308641853621243\n",
            "Accuracy: 99.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avalaiando conjunto de teste com Learning Ratte = 0.1 e 500 epocas."
      ],
      "metadata": {
        "id": "7NsilL1Jrh0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tamanhoDasCamadas = [X_train.shape[1], 16, 1]\n",
        "\n",
        "pesos, bias = train(X_train, y_train, tamanhoDasCamadas, learningRate=0.1, epocas=500)\n",
        "\n",
        "y_pred = predicao(X_test, pesos, bias)\n",
        "\n",
        "acuracia = np.mean(y_pred == y_test)\n",
        "print(f'Accuracy: {acuracia * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0PKLE2DrwGQ",
        "outputId": "7d2333f7-d483-490d-b321-d5468f13c860"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 0, Loss: 0.2501434577265461\n",
            "Epoca 100, Loss: 0.08528772440172797\n",
            "Epoca 200, Loss: 0.043759151992386405\n",
            "Epoca 300, Loss: 0.02824160502218727\n",
            "Epoca 400, Loss: 0.020600900935516264\n",
            "Accuracy: 99.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sabendo que o dataset é desbalanceado, podemos replicar os casos de fraude que acontecem menos frequentemente, porém o dataset dobraria de tamanho ficando com cerca de 400 mil observações. Outa alternativa ser seria diminuir o caso de maior frequencia, de forma a equilibrar o dataset, porém muita informação seria perdida nesse processo, ja que passaria de mais de 200 mil observações no total para cerca de 1000."
      ],
      "metadata": {
        "id": "jj4SF_5rtLq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "\n",
        "majoritaria = dataset[dataset['Class'] == 0]\n",
        "minoritaria = dataset[dataset['Class'] == 1]\n",
        "\n",
        "majoritariaUndersampled = resample(majoritaria, replace=False, n_samples=len(minoritaria), random_state=0)\n",
        "\n",
        "datasetBalanceado = pd.concat([majoritariaUndersampled, minoritaria])"
      ],
      "metadata": {
        "id": "zto92hcDzzXd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XBalanceado = datasetBalanceado.drop(['Time','Amount','Class'], axis=1).values\n",
        "yBalanceado = datasetBalanceado['Class'].values.reshape(-1, 1)\n",
        "\n",
        "print(XBalanceado.shape)\n",
        "print(yBalanceado.shape)\n",
        "\n",
        "X_trainBalanceado, X_testBalanceado, y_trainBalanceado, y_testBalanceado = train_test_split(XBalanceado, yBalanceado, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhpL6acY0jq_",
        "outputId": "db401c36-de33-4fe6-e16a-5fab18b53dc9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(984, 28)\n",
            "(984, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tamanhoDasCamadas = [X_trainBalanceado.shape[1], 16, 1]\n",
        "\n",
        "pesos, bias = train(X_trainBalanceado, y_trainBalanceado, tamanhoDasCamadas, learningRate=0.01, epocas=1000)\n",
        "\n",
        "y_predTrainBalanceado = predicao(X_trainBalanceado, pesos, bias)\n",
        "\n",
        "acuracia = np.mean(y_predTrainBalanceado == y_trainBalanceado)\n",
        "print(f'Accuracy: {acuracia * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn07Q-Mi1V3O",
        "outputId": "df91e30e-9983-4ca0-c7f3-fa39d8883795"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 0, Loss: 0.25044851598460577\n",
            "Epoca 100, Loss: 0.24378136692544097\n",
            "Epoca 200, Loss: 0.21014068896471325\n",
            "Epoca 300, Loss: 0.17534971052408513\n",
            "Epoca 400, Loss: 0.15891002546120958\n",
            "Epoca 500, Loss: 0.14871303768818275\n",
            "Epoca 600, Loss: 0.14112120320896482\n",
            "Epoca 700, Loss: 0.13488314844034177\n",
            "Epoca 800, Loss: 0.12948223983400264\n",
            "Epoca 900, Loss: 0.1246755600216264\n",
            "Accuracy: 93.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao realizar o Undersampling do dataset, o modelo perde bastante acurácia, porém a acurácia anterior poderia ser falsa, já que o valor obtido era o mesmo caso todos os casos fossem classificados como 0 (não fraude)."
      ],
      "metadata": {
        "id": "Emv2k8kG1squ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testando outros valores de Learning Rate e épocas."
      ],
      "metadata": {
        "id": "xoq_b42Q2FwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tamanhoDasCamadas = [X_trainBalanceado.shape[1], 16, 1]\n",
        "\n",
        "pesos, bias = train(X_trainBalanceado, y_trainBalanceado, tamanhoDasCamadas, learningRate=0.99, epocas=3000)\n",
        "\n",
        "y_predTrainBalanceado = predicao(X_trainBalanceado, pesos, bias)\n",
        "\n",
        "acuracia = np.mean(y_predTrainBalanceado == y_trainBalanceado)\n",
        "print(f'Accuracy: {acuracia * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6QKZlp12KOR",
        "outputId": "9a1fd769-75ea-40fc-ca5a-2511db631f63"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 0, Loss: 0.24978242025769673\n",
            "Epoca 100, Loss: 0.05003636238278257\n",
            "Epoca 200, Loss: 0.04347072894509122\n",
            "Epoca 300, Loss: 0.04028155534177372\n",
            "Epoca 400, Loss: 0.03723066006366523\n",
            "Epoca 500, Loss: 0.0343070320624898\n",
            "Epoca 600, Loss: 0.03179169563781678\n",
            "Epoca 700, Loss: 0.029438631080737486\n",
            "Epoca 800, Loss: 0.027100645548561668\n",
            "Epoca 900, Loss: 0.024576687884413875\n",
            "Epoca 1000, Loss: 0.02189546797718931\n",
            "Epoca 1100, Loss: 0.019447585166789138\n",
            "Epoca 1200, Loss: 0.0172511781670081\n",
            "Epoca 1300, Loss: 0.015393770858675692\n",
            "Epoca 1400, Loss: 0.01379752957481008\n",
            "Epoca 1500, Loss: 0.012367076758453954\n",
            "Epoca 1600, Loss: 0.011272122081481905\n",
            "Epoca 1700, Loss: 0.01032979415967882\n",
            "Epoca 1800, Loss: 0.009528889402792094\n",
            "Epoca 1900, Loss: 0.008844587063769224\n",
            "Epoca 2000, Loss: 0.008252275500557935\n",
            "Epoca 2100, Loss: 0.007724947051533806\n",
            "Epoca 2200, Loss: 0.007238530727709422\n",
            "Epoca 2300, Loss: 0.006800925984719128\n",
            "Epoca 2400, Loss: 0.006418673349381452\n",
            "Epoca 2500, Loss: 0.006078810014524079\n",
            "Epoca 2600, Loss: 0.005778791282614533\n",
            "Epoca 2700, Loss: 0.005516160049389144\n",
            "Epoca 2800, Loss: 0.005282052098324568\n",
            "Epoca 2900, Loss: 0.005071649297898215\n",
            "Accuracy: 99.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao mudar o Learning Rate de 0.01 para 0.99 e o número de épocas de 1000 para 3000. temos uma grande melhora na acurácia, saindo de 93.77% para 99.75%."
      ],
      "metadata": {
        "id": "P4Up_rrU3F8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizando TensorFlow para a implementação da rede neural."
      ],
      "metadata": {
        "id": "vE66cwUQ7KN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "print(X_train.shape)\n",
        "model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqLzWvjj7WmS",
        "outputId": "7710628e-5db7-467b-e0b0-75b6f93945c9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(227845, 28)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFU50itB_F1V",
        "outputId": "1dd5c8c0-d545-4c1f-ab92-a432fc53c332"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0750 - val_accuracy: 0.9993 - val_loss: 0.0038\n",
            "Epoch 2/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0043 - val_accuracy: 0.9993 - val_loss: 0.0033\n",
            "Epoch 3/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9994 - val_loss: 0.0031\n",
            "Epoch 4/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.9990 - val_loss: 0.0036\n",
            "Epoch 5/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.9988 - val_loss: 0.0038\n",
            "Epoch 6/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9994 - val_loss: 0.0029\n",
            "Epoch 7/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.9993 - val_loss: 0.0031\n",
            "Epoch 8/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9994 - val_loss: 0.0028\n",
            "Epoch 9/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9994 - val_loss: 0.0029\n",
            "Epoch 10/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9995 - val_loss: 0.0029\n",
            "Epoch 11/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9991 - val_loss: 0.0042\n",
            "Epoch 12/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9994 - val_loss: 0.0030\n",
            "Epoch 13/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9993 - val_loss: 0.0032\n",
            "Epoch 14/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9993 - val_loss: 0.0033\n",
            "Epoch 15/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9995 - val_loss: 0.0029\n",
            "Epoch 16/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9993 - val_loss: 0.0031\n",
            "Epoch 17/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9995 - val_loss: 0.0028\n",
            "Epoch 18/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9993 - val_loss: 0.0039\n",
            "Epoch 19/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9995 - val_loss: 0.0031\n",
            "Epoch 20/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9993 - val_loss: 0.0033\n",
            "Epoch 21/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9995 - val_loss: 0.0031\n",
            "Epoch 22/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9994 - val_loss: 0.0032\n",
            "Epoch 23/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9995 - val_loss: 0.0030\n",
            "Epoch 24/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9993 - val_loss: 0.0034\n",
            "Epoch 25/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9995 - val_loss: 0.0033\n",
            "Epoch 26/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9995 - val_loss: 0.0032\n",
            "Epoch 27/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9995 - val_loss: 0.0032\n",
            "Epoch 28/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9994 - val_loss: 0.0036\n",
            "Epoch 29/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9993 - val_loss: 0.0037\n",
            "Epoch 30/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9994 - val_loss: 0.0032\n",
            "Epoch 31/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9993 - val_loss: 0.0043\n",
            "Epoch 32/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9995 - val_loss: 0.0032\n",
            "Epoch 33/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9994 - val_loss: 0.0037\n",
            "Epoch 34/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9994 - val_loss: 0.0033\n",
            "Epoch 35/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9995 - val_loss: 0.0035\n",
            "Epoch 36/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9995 - val_loss: 0.0035\n",
            "Epoch 37/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9994 - val_loss: 0.0037\n",
            "Epoch 38/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9994 - val_loss: 0.0040\n",
            "Epoch 39/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9995 - val_loss: 0.0035\n",
            "Epoch 40/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9994 - val_loss: 0.0037\n",
            "Epoch 41/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9994 - val_loss: 0.0041\n",
            "Epoch 42/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9995 - val_loss: 0.0037\n",
            "Epoch 43/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9994 - val_loss: 0.0038\n",
            "Epoch 44/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9995 - val_loss: 0.0038\n",
            "Epoch 45/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9993 - val_loss: 0.0040\n",
            "Epoch 46/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9994 - val_loss: 0.0037\n",
            "Epoch 47/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9995 - val_loss: 0.0040\n",
            "Epoch 48/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9994 - val_loss: 0.0038\n",
            "Epoch 49/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9995 - val_loss: 0.0039\n",
            "Epoch 50/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9993 - val_loss: 0.0039\n",
            "Epoch 51/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9993 - val_loss: 0.0041\n",
            "Epoch 52/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9995 - val_loss: 0.0043\n",
            "Epoch 53/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9994 - val_loss: 0.0041\n",
            "Epoch 54/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9994 - val_loss: 0.0041\n",
            "Epoch 55/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9995 - val_loss: 0.0041\n",
            "Epoch 56/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9994 - val_loss: 0.0042\n",
            "Epoch 57/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9994 - val_loss: 0.0043\n",
            "Epoch 58/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9991 - val_loss: 0.0044\n",
            "Epoch 59/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9994 - val_loss: 0.0043\n",
            "Epoch 60/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9995 - val_loss: 0.0047\n",
            "Epoch 61/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9994 - val_loss: 0.0043\n",
            "Epoch 62/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.9086e-04 - val_accuracy: 0.9994 - val_loss: 0.0046\n",
            "Epoch 63/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 0.0045\n",
            "Epoch 64/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9995 - val_loss: 0.0045\n",
            "Epoch 65/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9993 - val_loss: 0.0045\n",
            "Epoch 66/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9995 - val_loss: 0.0045\n",
            "Epoch 67/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.7550e-04 - val_accuracy: 0.9994 - val_loss: 0.0048\n",
            "Epoch 68/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9993 - val_loss: 0.0049\n",
            "Epoch 69/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9995 - val_loss: 0.0048\n",
            "Epoch 70/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9995 - val_loss: 0.0049\n",
            "Epoch 71/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.8810e-04 - val_accuracy: 0.9994 - val_loss: 0.0046\n",
            "Epoch 72/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 0.0049\n",
            "Epoch 73/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9994 - val_loss: 0.0048\n",
            "Epoch 74/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9993 - val_loss: 0.0045\n",
            "Epoch 75/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.7120e-04 - val_accuracy: 0.9989 - val_loss: 0.0059\n",
            "Epoch 76/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9995 - val_loss: 0.0054\n",
            "Epoch 77/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9991 - val_loss: 0.0056\n",
            "Epoch 78/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9995 - val_loss: 0.0050\n",
            "Epoch 79/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9993 - val_loss: 0.0048\n",
            "Epoch 80/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9992 - val_loss: 0.0054\n",
            "Epoch 81/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9993 - val_loss: 0.0052\n",
            "Epoch 82/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 0.0052\n",
            "Epoch 83/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 0.0054\n",
            "Epoch 84/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.6332e-04 - val_accuracy: 0.9993 - val_loss: 0.0053\n",
            "Epoch 85/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 7.7802e-04 - val_accuracy: 0.9992 - val_loss: 0.0053\n",
            "Epoch 86/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.4287e-04 - val_accuracy: 0.9993 - val_loss: 0.0055\n",
            "Epoch 87/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9993 - val_loss: 0.0055\n",
            "Epoch 88/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9994 - val_loss: 0.0058\n",
            "Epoch 89/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 0.0056\n",
            "Epoch 90/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9994 - val_loss: 0.0058\n",
            "Epoch 91/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9993 - val_loss: 0.0055\n",
            "Epoch 92/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 0.0059\n",
            "Epoch 93/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9992 - val_loss: 0.0061\n",
            "Epoch 94/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.4345e-04 - val_accuracy: 0.9993 - val_loss: 0.0057\n",
            "Epoch 95/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9992 - val_loss: 0.0055\n",
            "Epoch 96/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 7.2569e-04 - val_accuracy: 0.9991 - val_loss: 0.0059\n",
            "Epoch 97/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 8.9182e-04 - val_accuracy: 0.9990 - val_loss: 0.0060\n",
            "Epoch 98/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9993 - val_loss: 0.0058\n",
            "Epoch 99/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.0719e-04 - val_accuracy: 0.9990 - val_loss: 0.0063\n",
            "Epoch 100/100\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 8.8806e-04 - val_accuracy: 0.9989 - val_loss: 0.0065\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e016b85ac50>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testando o modelo no conjunto de dados de teste"
      ],
      "metadata": {
        "id": "vUYb_11xPzLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR2CQiW8PACY",
        "outputId": "31f825e4-43a5-4afa-aa23-78977230b32e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0072\n",
            "Loss: 0.0068, Accuracy: 0.9991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Considerações finais:\n",
        "\n",
        "O modelo utilizando o TensorFlow teve os melhores resultados, com uma acurácia de 0.9991. Porém os modelo feito from scratch tbm tiveram bons resultados. E o modelo from scratch cujo teve o dataset balanceado, teve um resultado parecido com uma acuracia de o.9975 e uma chance de ter overfiting nesse modelo baixíssima. E no modelo from scratch cujo dataset não foi balanceado, o ajuste da quantidade de épocas e o Learning Rate mostrou uma grande melhoria para a acurácia do modelo."
      ],
      "metadata": {
        "id": "Cc8H4tLmQB_f"
      }
    }
  ]
}